apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: modelcar-pipelinerun1
spec:
  pipelineRef:
    name: modelcar-pipeline
  timeout: 3h  # Add a 2-hour timeout
  params:
    - name: HUGGINGFACE_MODEL
      value: "meta-llama/Llama-3.1-8B-Instruct"
    - name: OCI_IMAGE
      value: "quay.io/hayesphilip/llama-3.1-8B-Instruct"
    - name: HUGGINGFACE_ALLOW_PATTERNS
      value: "*.safetensors *.json *.txt"
    - name: COMPRESS_MODEL
      value: "true"
    - name: MODEL_NAME
      value: "Llama-3.1-8B-Instruct"
    - name: MODEL_VERSION
      value: "4.0.1"
    - name: MODEL_REGISTRY_URL
      value: "https://registry-rest.apps.xxx.com"
    - name: DEPLOY_MODEL
      value: "true"
    - name: SKIP_TASKS
      value: "cleanup-workspace,pull-model-from-huggingface,compress-model,build-and-push-modelcar"
  workspaces:
    - name: shared-workspace
      persistentVolumeClaim:
        claimName: modelcar-storage
    - name: quay-auth-workspace
      secret:
        secretName: quay-auth
  podTemplate:
    tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
    nodeSelector:
      nvidia.com/gpu.present: "true"
